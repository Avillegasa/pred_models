# ğŸ¤– Phishing Email Detection - Modelado de Machine Learning

Proyecto completo de modelado para detecciÃ³n de emails phishing usando Machine Learning.
**VersiÃ³n local** (sin Azure ML) con 4 modelos: Logistic Regression, Random Forest, SVM y Gradient Boosting.

---

## ğŸ“‹ Tabla de Contenidos

- [DescripciÃ³n General](#-descripciÃ³n-general)
- [Estructura del Proyecto](#-estructura-del-proyecto)
- [InstalaciÃ³n](#-instalaciÃ³n)
- [Uso](#-uso)
- [Modelos Incluidos](#-modelos-incluidos)
- [Feature Engineering](#-feature-engineering)
- [ConfiguraciÃ³n](#-configuraciÃ³n)
- [Resultados](#-resultados)
- [Archivos Generados](#-archivos-generados)

---

## ğŸ¯ DescripciÃ³n General

Este proyecto implementa un sistema de clasificaciÃ³n binaria para detectar emails de phishing vs emails legÃ­timos. Basado en el dataset CEAS_08 con 39,154 emails limpios.

### CaracterÃ­sticas Principales

- âœ… **4 modelos de ML**: Logistic Regression, Random Forest, SVM, Gradient Boosting
- âœ… **Feature Engineering completo**: TF-IDF + metadata + sentiment analysis
- âœ… **Sin Azure ML**: EjecuciÃ³n 100% local
- âœ… **EvaluaciÃ³n exhaustiva**: ROC curves, confusion matrices, mÃ©tricas completas
- âœ… **Modular y extensible**: FÃ¡cil agregar nuevos modelos o features
- âœ… **ConfiguraciÃ³n centralizada**: Todo configurable desde `config.yaml`

### Dataset

- **Total**: 39,154 emails
- **Train**: 31,323 (80%)
- **Test**: 7,831 (20%)
- **Clases**:
  - 0 = LegÃ­timo (44.22%)
  - 1 = Phishing (55.78%)

---

## ğŸ“ Estructura del Proyecto

```
modeling/
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.yaml                    # ConfiguraciÃ³n centralizada
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â””â”€â”€ feature_engineering.py    # ExtracciÃ³n de features
â”‚   â””â”€â”€ models/
â”‚       â””â”€â”€ train.py                   # Entrenamiento de modelos
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ Phishing_Detection_Modeling.ipynb  # Notebook principal
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ models/                        # Modelos entrenados (.pkl)
â”‚   â”œâ”€â”€ reports/                       # Visualizaciones y reportes
â”‚   â””â”€â”€ features/                      # Features procesadas
â”œâ”€â”€ requirements.txt                   # Dependencias
â””â”€â”€ README.md                          # Esta documentaciÃ³n
```

---

## ğŸš€ InstalaciÃ³n

### 1. Requisitos Previos

- Python 3.9+
- pip o conda

### 2. Instalar Dependencias

```bash
cd modeling
pip install -r requirements.txt
```

**Dependencias principales**:
- pandas, numpy, scikit-learn
- matplotlib, seaborn
- jupyter, jupyterlab
- pyyaml

---

## ğŸ’» Uso

### OpciÃ³n 1: Notebook Interactivo (Recomendado)

```bash
# Navegar al directorio de notebooks
cd modeling/notebooks

# Iniciar Jupyter
jupyter notebook Phishing_Detection_Modeling.ipynb
```

Ejecutar las celdas secuencialmente. El notebook incluye:
1. Carga de datos
2. Feature engineering
3. Entrenamiento de 4 modelos
4. ComparaciÃ³n de mÃ©tricas
5. SelecciÃ³n del mejor modelo
6. Guardado de resultados

### OpciÃ³n 2: Scripts Individuales

**Feature Engineering**:
```bash
python src/features/feature_engineering.py \
    --input_data ../processed_data/train.csv \
    --output_dir outputs/features \
    --max_features 1000 \
    --ngram_min 1 \
    --ngram_max 2
```

**Entrenamiento** (requiere features pre-procesadas):
```bash
python src/models/train.py \
    --features_path outputs/features/features.csv \
    --output_dir outputs \
    --random_state 42
```

---

## ğŸ¤– Modelos Incluidos

| Modelo | DescripciÃ³n | HiperparÃ¡metros Principales |
|--------|-------------|------------------------------|
| **Logistic Regression** | Baseline rÃ¡pido y interpretable | `max_iter=1000`, `penalty='l2'` |
| **Random Forest** | Ensemble de Ã¡rboles | `n_estimators=100`, `max_depth=10` |
| **SVM** | Support Vector Machine | `kernel='rbf'`, `probability=True` |
| **Gradient Boosting** | Boosting secuencial | `n_estimators=100`, `learning_rate=0.1` |

Todos los modelos son configurables desde `config/config.yaml`.

---

## ğŸ”§ Feature Engineering

### Features Creadas (Total: ~1,015)

#### 1. Features NumÃ©ricas (15)
- `subject_length`, `subject_words`, `subject_special`
- `body_length`, `body_words`, `body_special`
- `url_count`, `urls` (binario)
- `sender_domain_encoded` (top 50 dominios)
- `subject_sentiment`, `body_sentiment` (basado en keywords)
- `subject_body_ratio`, `special_chars_ratio`
- `has_urgent`, `has_free`, `has_click` (keywords binarios)

#### 2. Features TF-IDF (~1,000)
- VectorizaciÃ³n de subject + body combinados
- ConfiguraciÃ³n:
  - `max_features`: 1,000
  - `ngram_range`: (1, 2) - unigrams y bigrams
  - `min_df`: 5 (mÃ­nima frecuencia documental)
  - `stop_words`: 'english'

### Proceso de Feature Engineering

1. **Limpieza**: Rellenar nulos en subject/body/sender
2. **ExtracciÃ³n de texto**: Longitudes, palabras, caracteres especiales
3. **Metadata**: Dominio del sender, conteo de URLs
4. **Sentiment**: Score basado en keywords phishing vs legÃ­timos
5. **Features derivadas**: Ratios, presencia de keywords crÃ­ticas
6. **TF-IDF**: VectorizaciÃ³n del contenido textual
7. **Encoding**: Label encoding de dominios frecuentes

---

## âš™ï¸ ConfiguraciÃ³n

Toda la configuraciÃ³n estÃ¡ en `config/config.yaml`:

```yaml
project:
  name: "phishing_detection_local"
  version: "1.0.0"

data:
  train_file: "train.csv"
  test_file: "test.csv"
  random_state: 42

features:
  tfidf:
    max_features: 1000
    ngram_range: [1, 2]
    min_df: 5

models:
  random_state: 42
  logistic_regression:
    max_iter: 1000
  random_forest:
    n_estimators: 100
    max_depth: 10
  svm:
    kernel: 'rbf'
  gradient_boosting:
    n_estimators: 100
    learning_rate: 0.1

evaluation:
  primary_metric: 'f1_score'
```

### Modificar ConfiguraciÃ³n

Editar `config/config.yaml` para:
- Cambiar hiperparÃ¡metros de modelos
- Ajustar TF-IDF (max_features, ngrams, etc.)
- Cambiar mÃ©trica de selecciÃ³n (f1_score, accuracy, roc_auc)

---

## ğŸ“Š Resultados

Al finalizar el entrenamiento, se genera:

### 1. MÃ©tricas de Todos los Modelos

ComparaciÃ³n en tabla y grÃ¡ficos:
- Accuracy
- Precision
- Recall
- F1-Score
- ROC-AUC

### 2. Visualizaciones

- **Confusion Matrices**: Por cada modelo
- **ROC Curves**: ComparaciÃ³n de todos los modelos
- **GrÃ¡ficos de barras**: ComparaciÃ³n de mÃ©tricas

### 3. Mejor Modelo

SelecciÃ³n automÃ¡tica basado en F1-Score (configurable).

**Ejemplo de resultados esperados**:
```
ğŸ† Mejor Modelo: Logistic Regression
ğŸ¯ F1-Score: 0.9759
ğŸ“ˆ Accuracy: 0.9729
```

---

## ğŸ“¦ Archivos Generados

Todos los outputs se guardan en `outputs/`:

### `outputs/models/`
```
best_model.pkl               # Mejor modelo serializado
logistic_regression.pkl      # Todos los modelos individuales
random_forest.pkl
svm.pkl
gradient_boosting.pkl
model_info.json              # Metadata completa con mÃ©tricas
```

### `outputs/reports/`
```
logistic_regression_confusion_matrix.png
random_forest_confusion_matrix.png
svm_confusion_matrix.png
gradient_boosting_confusion_matrix.png
roc_curves_comparison.png
models_comparison_report.txt  # Reporte en texto plano
```

### `outputs/features/`
```
train_features.csv           # Features procesadas de train
test_features.csv            # Features procesadas de test
tfidf_vectorizer.pkl         # Vectorizador TF-IDF entrenado
```

---

## ğŸ“ˆ CÃ³mo Usar el Modelo Entrenado

### Cargar el Mejor Modelo

```python
import joblib
import pandas as pd

# Cargar modelo
model = joblib.load('outputs/models/best_model.pkl')

# Cargar vectorizador TF-IDF
tfidf_vectorizer = joblib.load('outputs/features/tfidf_vectorizer.pkl')

# Procesar nuevos emails
from src.features.feature_engineering import engineer_features

new_emails_df = pd.read_csv('new_emails.csv')
new_features, _ = engineer_features(
    new_emails_df,
    tfidf_vectorizer=tfidf_vectorizer,
    fit_tfidf=False  # Solo transform
)

# Predecir
X_new = new_features.drop('label', axis=1)  # Si no tiene label, omitir
predictions = model.predict(X_new)
probabilities = model.predict_proba(X_new)

print(f"PredicciÃ³n: {predictions}")  # 0=LegÃ­timo, 1=Phishing
print(f"Probabilidades: {probabilities}")
```

---

## ğŸ” AnÃ¡lisis de Errores

El notebook incluye anÃ¡lisis de:

- **False Positives**: Emails legÃ­timos marcados como phishing
- **False Negatives**: Emails phishing marcados como legÃ­timos

Revisar estos casos ayuda a mejorar el modelo.

---

## ğŸ› ï¸ Troubleshooting

### Error: MÃ³dulos no encontrados

```bash
# Asegurarse de estar en el directorio correcto
cd modeling/notebooks

# Verificar que sys.path incluye ../src
import sys
sys.path.append('../src')
```

### Error: Archivo no encontrado

Verificar que los datos procesados estÃ¡n en:
```
Phishing/processed_data/
â”œâ”€â”€ train.csv
â”œâ”€â”€ test.csv
â””â”€â”€ CEAS_08_clean.csv
```

### Error: TF-IDF vocabulary mismatch

Asegurarse de:
1. Usar el mismo vectorizador para train y test
2. `fit_tfidf=True` en train, `fit_tfidf=False` en test

---

## ğŸ“š PrÃ³ximos Pasos

1. **OptimizaciÃ³n de hiperparÃ¡metros**: GridSearch o RandomSearch
2. **Feature selection**: Eliminar features poco importantes
3. **Ensemble stacking**: Combinar predicciones de mÃºltiples modelos
4. **Deep Learning**: LSTM, BERT para anÃ¡lisis de texto avanzado
5. **Deploy**: API REST con Flask/FastAPI para predicciones en tiempo real

---

## ğŸ‘¥ Autores

Proyecto creado para trabajo acadÃ©mico de predicciÃ³n de incidentes de ciberseguridad.

---

## ğŸ“… Fecha

Enero 2026

---

## ğŸ“„ Licencia

Uso acadÃ©mico y educativo.

---

**Â¿Preguntas o problemas?** Revisar la documentaciÃ³n en cada script (`feature_engineering.py`, `train.py`) o contactar al equipo.
