"""
PIPELINE PRINCIPAL DE MODELADO - ACCOUNT TAKEOVER DETECTION

Script principal que ejecuta el pipeline completo:
1. Carga del dataset balanceado RBA
2. Feature Engineering completo
3. Split Train/Test estratificado
4. Entrenamiento de 4 modelos (LR, RF, SVM, GB)
5. Comparaci√≥n y selecci√≥n del mejor modelo
6. Guardado de resultados completos

Uso:
    python3 main_pipeline.py
"""

import sys
import os
import pandas as pd
import numpy as np
from sklearn.model_selection import train_test_split
from datetime import datetime
import warnings

# Agregar src al path para imports
sys.path.append(os.path.join(os.path.dirname(__file__), 'src'))

from features.feature_engineering import engineer_features, save_features_and_encoders
from models.train import train_models, select_best_model, save_results

warnings.filterwarnings('ignore')


def print_section_header(title):
    """Imprimir header de secci√≥n con estilo"""
    print("\n" + "=" * 80)
    print(f"  {title}")
    print("=" * 80 + "\n")


def main():
    """Pipeline principal de modelado"""

    print_section_header("üîê ACCOUNT TAKEOVER DETECTION - PIPELINE DE MODELADO")
    print(f"üìÖ Fecha de ejecuci√≥n: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")

    # ============================================================================
    # PASO 1: CARGAR DATASET BALANCEADO
    # ============================================================================
    print_section_header("PASO 1: CARGA DE DATASET BALANCEADO")

    # Path relativo al dataset balanceado
    data_path = os.path.join(
        os.path.dirname(__file__),
        '../processed_data/rba_balanced.csv'
    )

    print(f"üìÇ Cargando dataset desde: {data_path}")

    if not os.path.exists(data_path):
        print(f"‚ùå ERROR: No se encontr√≥ el dataset en {data_path}")
        print("   Ejecuta primero: create_balanced_dataset.py")
        sys.exit(1)

    df = pd.read_csv(data_path)

    print(f"‚úÖ Dataset cargado exitosamente")
    print(f"   ‚Ä¢ Registros: {len(df):,}")
    print(f"   ‚Ä¢ Columnas: {len(df.columns)}")
    print(f"   ‚Ä¢ Account Takeover: {df['Is Account Takeover'].sum()} ({df['Is Account Takeover'].sum()/len(df)*100:.4f}%)")
    print(f"   ‚Ä¢ Normal: {len(df) - df['Is Account Takeover'].sum():,} ({(len(df) - df['Is Account Takeover'].sum())/len(df)*100:.4f}%)")

    # ============================================================================
    # PASO 2: FEATURE ENGINEERING
    # ============================================================================
    print_section_header("PASO 2: FEATURE ENGINEERING")

    features_df, encoders = engineer_features(df, fit_encoders=True)

    print(f"\n‚úÖ Feature Engineering completado")
    print(f"   ‚Ä¢ Features creadas: {features_df.shape[1] - 1}")  # -1 por el label
    print(f"   ‚Ä¢ Registros procesados: {len(features_df):,}")

    # Guardar features y encoders
    output_features_dir = os.path.join(os.path.dirname(__file__), 'outputs/features')
    save_features_and_encoders(features_df, encoders, output_features_dir)

    # ============================================================================
    # PASO 3: SPLIT TRAIN/TEST ESTRATIFICADO
    # ============================================================================
    print_section_header("PASO 3: SPLIT TRAIN/TEST")

    # Separar X y y
    X = features_df.drop('label', axis=1)
    y = features_df['label']

    # Split estratificado para mantener proporci√≥n de clases
    X_train, X_test, y_train, y_test = train_test_split(
        X, y,
        test_size=0.2,
        random_state=42,
        stratify=y  # Mantener proporci√≥n de ATO vs Normal
    )

    print(f"‚úÖ Split realizado con stratification")
    print(f"\n   üìä TRAIN SET:")
    print(f"      ‚Ä¢ Total: {len(X_train):,} samples")
    print(f"      ‚Ä¢ Account Takeover: {y_train.sum()} ({y_train.sum()/len(y_train)*100:.4f}%)")
    print(f"      ‚Ä¢ Normal: {len(y_train) - y_train.sum():,} ({(len(y_train) - y_train.sum())/len(y_train)*100:.4f}%)")

    print(f"\n   üìä TEST SET:")
    print(f"      ‚Ä¢ Total: {len(X_test):,} samples")
    print(f"      ‚Ä¢ Account Takeover: {y_test.sum()} ({y_test.sum()/len(y_test)*100:.4f}%)")
    print(f"      ‚Ä¢ Normal: {len(y_test) - y_test.sum():,} ({(len(y_test) - y_test.sum())/len(y_test)*100:.4f}%)")

    # ============================================================================
    # PASO 4: ENTRENAMIENTO DE MODELOS
    # ============================================================================
    print_section_header("PASO 4: ENTRENAMIENTO DE MODELOS")

    # Configuraci√≥n de modelos con class_weight='balanced' para manejar desbalance
    config = {
        'random_state': 42,
        'logistic_regression': {
            'max_iter': 1000,
            'n_jobs': -1,
            'class_weight': 'balanced',
            'solver': 'lbfgs'
        },
        'random_forest': {
            'n_estimators': 100,
            'max_depth': 10,
            'n_jobs': -1,
            'class_weight': 'balanced',
            'min_samples_split': 5,
            'min_samples_leaf': 2
        },
        'svm': {
            'kernel': 'rbf',
            'probability': True,
            'class_weight': 'balanced',
            'gamma': 'scale',
            'C': 1.0
        },
        'gradient_boosting': {
            'n_estimators': 100,
            'max_depth': 5,
            'learning_rate': 0.1,
            'subsample': 0.8,
            'min_samples_split': 5
        }
    }

    print("‚öôÔ∏è  Configuraci√≥n de modelos:")
    print("   ‚Ä¢ Logistic Regression: class_weight='balanced', max_iter=1000")
    print("   ‚Ä¢ Random Forest: class_weight='balanced', n_estimators=100, max_depth=10")
    print("   ‚Ä¢ SVM: class_weight='balanced', kernel='rbf'")
    print("   ‚Ä¢ Gradient Boosting: n_estimators=100, max_depth=5, learning_rate=0.1")

    # Entrenar modelos
    models_results = train_models(X_train, X_test, y_train, y_test, config=config)

    # ============================================================================
    # PASO 5: SELECCI√ìN DEL MEJOR MODELO
    # ============================================================================
    print_section_header("PASO 5: SELECCI√ìN DEL MEJOR MODELO")

    # Seleccionar basado en F1-Score (balance entre Precision y Recall)
    best_model_name, best_model, best_metrics = select_best_model(
        models_results,
        metric='f1_score'
    )

    print(f"\nüéØ M√âTRICAS DEL MEJOR MODELO ({best_model_name}):")
    print(f"   ‚Ä¢ F1-Score:  {best_metrics['f1_score']:.4f}")
    print(f"   ‚Ä¢ Precision: {best_metrics['precision']:.4f}")
    print(f"   ‚Ä¢ Recall:    {best_metrics['recall']:.4f}")
    print(f"   ‚Ä¢ Accuracy:  {best_metrics['accuracy']:.4f}")
    if best_metrics.get('roc_auc'):
        print(f"   ‚Ä¢ ROC-AUC:   {best_metrics['roc_auc']:.4f}")
        print(f"   ‚Ä¢ AUC-PR:    {best_metrics['average_precision']:.4f}")

    # ============================================================================
    # PASO 6: GUARDAR RESULTADOS
    # ============================================================================
    print_section_header("PASO 6: GUARDADO DE RESULTADOS")

    output_dir = os.path.join(os.path.dirname(__file__), 'outputs')
    model_info = save_results(models_results, best_model_name, output_dir, X_train, y_test)

    # ============================================================================
    # RESUMEN FINAL
    # ============================================================================
    print_section_header("‚úÖ PIPELINE COMPLETADO EXITOSAMENTE")

    print("üìä RESUMEN:")
    print(f"   ‚Ä¢ Dataset: {len(df):,} registros balanceados")
    print(f"   ‚Ä¢ Features: {X_train.shape[1]}")
    print(f"   ‚Ä¢ Modelos entrenados: 4 (LR, RF, SVM, GB)")
    print(f"   ‚Ä¢ Mejor modelo: {best_model_name}")
    print(f"   ‚Ä¢ F1-Score: {best_metrics['f1_score']:.4f}")

    print(f"\nüíæ ARCHIVOS GENERADOS:")
    print(f"   ‚Ä¢ Modelo: outputs/models/best_model.pkl")
    print(f"   ‚Ä¢ Encoders: outputs/features/label_encoders.pkl")
    print(f"   ‚Ä¢ Features: outputs/features/features.csv")
    print(f"   ‚Ä¢ Reportes: outputs/reports/")
    print(f"   ‚Ä¢ Metadata: outputs/models/model_info.json")

    print(f"\nüìã PR√ìXIMOS PASOS:")
    print(f"   1. Revisar reportes en: outputs/reports/")
    print(f"   2. Analizar confusion matrices y curvas ROC/PR")
    print(f"   3. Crear API REST usando el mejor modelo")
    print(f"   4. Integrar con frontend React dashboard")

    print("\n" + "=" * 80)
    print(f"üéâ ¬°Modelado completado! Timestamp: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print("=" * 80 + "\n")


if __name__ == "__main__":
    main()
