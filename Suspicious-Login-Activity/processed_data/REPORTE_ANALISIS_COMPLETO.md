# ðŸ“Š REPORTE COMPLETO: AnÃ¡lisis y Recomendaciones - Account Takeover Detection

**Fecha**: 2026-01-13
**Dataset**: RBA Reducido (<100K registros)
**AnÃ¡lisis por**: Claude Code

---

## ðŸ“‘ ÃNDICE

1. [Resumen Ejecutivo](#resumen-ejecutivo)
2. [Dataset Reducido](#dataset-reducido)
3. [AnÃ¡lisis GeogrÃ¡fico Profundo](#anÃ¡lisis-geogrÃ¡fico-profundo)
4. [Hallazgos del EDA](#hallazgos-del-eda)
5. [Recomendaciones para Notebook de Modelado](#recomendaciones-para-notebook-de-modelado)
6. [Plan de AcciÃ³n](#plan-de-acciÃ³n)

---

## 1. RESUMEN EJECUTIVO

### âœ… Tareas Completadas

1. **Dataset Reducido Creado**: 85,141 registros (<100K âœ“)
   - 141 ATOs (100% del original)
   - 85,000 casos normales
   - Ratio 1:603 (Normal:ATO)
   - TamaÃ±o: 23.73 MB

2. **AnÃ¡lisis GeogrÃ¡fico Profundo**: Patrones identificados
   - Rumania (RO) domina ATOs: 56% (139.7x sobre-representado)
   - Noruega (NO) domina normales: 45.2%
   - 98.6% de ATOs tienen cambio de paÃ­s
   - RTT promedio: ATOs 673ms, Normal 651ms

3. **EDA Completo Ejecutado**: 9 fases de anÃ¡lisis
   - 16 columnas raw + 3 derivadas temporales
   - 47,858 usuarios Ãºnicos, 55,362 IPs Ãºnicas
   - 99.3% de ATOs son logins exitosos
   - 57.4% de logins normales fallan

### ðŸŽ¯ Objetivo del Proyecto

**Detectar Account Takeover** (NO Brute Force):
- Uso anÃ³malo de credenciales vÃ¡lidas
- Patrones: paÃ­s diferente, IP nueva, dispositivo diferente
- Los atacantes YA tienen credenciales robadas

---

## 2. DATASET REDUCIDO

### ðŸ“Š EstadÃ­sticas Generales

```
Total Registros: 85,141 (<100K âœ“)
Account Takeover: 141 (0.17%)
Normal: 85,000 (99.83%)
Ratio: 1:603 (Normal:ATO)
TamaÃ±o: 23.73 MB
Usuarios Ãºnicos: 47,858
IPs Ãºnicas: 55,362
PaÃ­ses Ãºnicos: 141
Regiones Ãºnicas: 668
Ciudades Ãºnicas: 3,686
Periodo: 2020-02-03 a 2020-12-13 (313 dÃ­as)
```

### ðŸ“ Archivos Generados

| Archivo | DescripciÃ³n | TamaÃ±o |
|---------|-------------|--------|
| `rba_reduced.csv` | Dataset reducido principal | 23.73 MB |
| `geographic_analysis_report.txt` | AnÃ¡lisis geogrÃ¡fico | ~15 KB |
| `eda_reduced_report.txt` | EDA completo | ~20 KB |
| `REPORTE_ANALISIS_COMPLETO.md` | Este reporte | ~25 KB |

---

## 3. ANÃLISIS GEOGRÃFICO PROFUNDO

### ðŸŒ DistribuciÃ³n por PaÃ­s

#### PaÃ­ses en Account Takeover (Top 10)

| PaÃ­s | Casos ATO | % ATOs | Sobre-representaciÃ³n |
|------|-----------|--------|---------------------|
| **RO** (Rumania) | 79 | 56.0% | **139.7x** |
| NO (Noruega) | 10 | 7.1% | 0.16x |
| CA (CanadÃ¡) | 9 | 6.4% | **13.1x** |
| BR (Brasil) | 9 | 6.4% | 1.6x |
| ID (Indonesia) | 9 | 6.4% | **5.8x** |
| IT (Italia) | 7 | 5.0% | **10.0x** |
| DK (Dinamarca) | 5 | 3.5% | **31.7x** |
| LV (Letonia) | 3 | 2.1% | **113.0x** |
| CL (Chile) | 3 | 2.1% | **43.1x** |
| CZ (RepÃºblica Checa) | 2 | 1.4% | 8.6x |

**Insight Clave**: Rumania (RO) es el paÃ­s dominante en ATOs, 139.7x mÃ¡s frecuente que en casos normales.

#### PaÃ­ses en Casos Normales (Top 10)

| PaÃ­s | Casos Normales | % Normal |
|------|----------------|----------|
| **NO** (Noruega) | 38,428 | 45.21% |
| **US** (Estados Unidos) | 21,819 | 25.67% |
| BR (Brasil) | 3,429 | 4.03% |
| RU (Rusia) | 2,887 | 3.40% |
| PL (Polonia) | 2,694 | 3.17% |
| DE (Alemania) | 2,266 | 2.67% |
| IN (India) | 1,326 | 1.56% |
| AU (Australia) | 1,268 | 1.49% |
| GB (Reino Unido) | 1,251 | 1.47% |
| UA (Ucrania) | 1,242 | 1.46% |

**Insight Clave**: Noruega (NO) domina casos normales (45%), esperado para dataset SSO noruego.

### ðŸ”„ Cambios de PaÃ­s

- **Total cambios de paÃ­s**: 75,781
- **Usuarios con cambio de paÃ­s**: 47,858
- **ATOs con cambio de paÃ­s**: 139 de 141 (**98.6%**)

**ConclusiÃ³n**: Cambio de paÃ­s es **SEÃ‘AL MUY FUERTE** de Account Takeover.

#### Cambios de PaÃ­s MÃ¡s Comunes (Top 10)

1. BR â†’ US: 5,972 veces
2. BR â†’ NO: 4,289 veces
3. BR â†’ BR: 1,567 veces
4. BR â†’ DE: 1,312 veces
5. NO â†’ NO: 1,174 veces
6. BR â†’ RU: 1,146 veces
7. NO â†’ US: 1,010 veces
8. BR â†’ PL: 844 veces
9. BR â†’ IN: 671 veces
10. BR â†’ AU: 588 veces

### â±ï¸ Round-Trip Time (RTT)

| MÃ©trica | ATOs | Normal | Diferencia |
|---------|------|--------|------------|
| Media | 673.0ms | 651.4ms | +21.6ms (+3.3%) |
| Mediana | 673.0ms | 539.0ms | +134.0ms (+24.9%) |

**ConclusiÃ³n**: RTT puede ser feature Ãºtil (diferencia moderada en mediana).

### ðŸŽ¯ IPs de Ataque

- **Total IPs marcadas como ataque**: 8,020 (9.4% del dataset)
- **ATOs con Attack IP**: 77 de 141 (54.6%)

#### Top 10 PaÃ­ses con IPs de Ataque

1. **US**: 6,105 IPs (76.1%)
2. **NO**: 466 IPs (5.8%)
3. **PL**: 301 IPs (3.8%)
4. **RO**: 236 IPs (2.9%)
5. **ID**: 202 IPs (2.5%)

### ðŸ“ Regiones y Ciudades en ATOs

**Top 5 Regiones**:
1. `-` (no especificado): 75 casos (53.2%)
2. Ilfov (Rumania): 15 casos (10.6%)
3. Vestland (Noruega): 7 casos (5.0%)
4. Mato Grosso do Sul (Brasil): 4 casos (2.8%)
5. Bucuresti (Rumania): 4 casos (2.8%)

**Top 5 Ciudades**:
1. `-` (no especificado): 75 casos (53.2%)
2. Petrachioaia (Rumania): 15 casos (10.6%)
3. Vassenden (Noruega): 7 casos (5.0%)
4. Bucharest (Rumania): 4 casos (2.8%)
5. Riga (Letonia): 3 casos (2.1%)

---

## 4. HALLAZGOS DEL EDA

### ðŸŽ¯ Target Variable: Is Account Takeover

- **141 casos de ATO** (0.17% del dataset)
- **85,000 casos normales** (99.83%)
- **Ratio 1:603** (Normal:ATO)
- **Desbalance extremo** â†’ Requiere tÃ©cnicas especiales

### âœ… Login Success/Failure

#### En ATOs:
- **99.3% EXITOSOS** (140/141)
- **0.7% FALLIDOS** (1/141)

**ConclusiÃ³n**: Los atacantes YA tienen credenciales vÃ¡lidas robadas.

#### En Casos Normales:
- **42.5% EXITOSOS** (36,157/85,000)
- **57.5% FALLIDOS** (48,843/85,000)

**ConclusiÃ³n**: Usuarios normales fallan frecuentemente (typos, olvidos, caps lock).

### ðŸŒ Features CategÃ³ricos

#### Browsers (Top 5)
1. Chrome Mobile 81.0.4044: 4,361 (5.1%)
2. Chrome 84.0.4147.338.339: 3,085 (3.6%)
3. Opera Mobile 52.1.2254: 3,043 (3.6%)
4. ZipppBot 0.11: 2,785 (3.3%)
5. Android 2.3.3.2660: 2,601 (3.1%)

#### Sistemas Operativos (Top 5)
1. iOS 11.2.6: 12,630 (14.8%)
2. Mac OS X 10.14.6: 12,190 (14.3%)
3. iOS 13.4: 9,525 (11.2%)
4. Other: 5,357 (6.3%)
5. Android 4.1: 5,048 (5.9%)

#### Device Type
1. **Mobile**: 54,905 (64.5%)
2. **Desktop**: 22,314 (26.2%)
3. **Bot**: 3,807 (4.5%)
4. **Tablet**: 2,518 (3.0%)
5. **Unknown**: 1,591 (1.9%)

### ðŸ“Š Features NumÃ©ricos

#### Round-Trip Time [ms]
- **Media**: 651.4ms
- **Mediana**: 539.0ms
- **Std Dev**: 754.9ms
- **Min**: 10ms
- **Max**: 18,264ms
- **Nulls**: 81,384 (95.6%) âš ï¸ **Alto porcentaje de valores faltantes**

#### ASN (Autonomous System Number)
- **ASNs Ãºnicos**: 1,762
- **Top ASN**: 29695 (27.9%), 393398 (21.4%)

### â° AnÃ¡lisis Temporal

#### Periodo
- **Inicio**: 2020-02-03
- **Fin**: 2020-12-13
- **DuraciÃ³n**: 313 dÃ­as

#### DistribuciÃ³n por Hora (Top 5 horas mÃ¡s activas)
1. Hora 09:00: 4,749 logins (5.6%)
2. Hora 08:00: 4,572 logins (5.4%)
3. Hora 07:00: 4,332 logins (5.1%)
4. Hora 06:00: 3,601 logins (4.2%)
5. Hora 10:00: 4,508 logins (5.3%)

**PatrÃ³n**: Actividad aumenta en horas de la maÃ±ana (6-10 AM).

#### DistribuciÃ³n por DÃ­a de Semana
- **Tuesday**: 13,147 (15.4%) - MÃ¡s activo
- **Thursday**: 12,855 (15.1%)
- **Wednesday**: 12,673 (14.9%)
- **Monday**: 12,616 (14.8%)
- **Friday**: 12,203 (14.3%)
- **Sunday**: 11,104 (13.0%)
- **Saturday**: 10,543 (12.4%) - Menos activo

**PatrÃ³n**: DÃ­as laborales mÃ¡s activos que fines de semana.

### ðŸ‘¥ Usuarios e IPs

#### EstadÃ­sticas
- **Usuarios Ãºnicos**: 47,858
- **IPs Ãºnicas**: 55,362
- **Ratio IP/Usuario**: 1.16

#### Usuarios con MÃºltiples IPs
- **1 IP**: 47,114 usuarios
- **2+ IPs**: 744 usuarios
- **5+ IPs**: 5 usuarios
- **10+ IPs**: 1 usuario

#### IPs con MÃºltiples Usuarios
- **1 usuario**: 50,211 IPs
- **2+ usuarios**: 5,151 IPs
- **5+ usuarios**: 1,351 IPs (posible credential stuffing)
- **10+ usuarios**: 67 IPs

---

## 5. RECOMENDACIONES PARA NOTEBOOK DE MODELADO

### âœ… LO QUE YA ESTÃ BIEN (Mantener)

1. **Class Weights Balanced** âœ“
   - Logistic Regression, Random Forest, SVM tienen `class_weight='balanced'`
   - Ayuda con el desbalance extremo (1:603)

2. **35 Features Creadas** âœ“
   - Temporales, comportamiento, agregados por usuario
   - Coincide con recomendaciones del EDA

3. **MÃ©tricas Completas** âœ“
   - F1-Score, Precision, Recall, ROC-AUC, AUC-PR
   - FPR, FNR, Confusion Matrix

4. **Visualizaciones** âœ“
   - Matrices de confusiÃ³n, curvas ROC/PR, comparaciÃ³n de modelos

### âš ï¸ LO QUE DEBE CAMBIARSE (CrÃ­tico)

#### 1. TEMPORAL SPLIT (No Random Split) ðŸ”´ ALTA PRIORIDAD

**Problema actual**: Usa `train_test_split` con `stratify=y` (split aleatorio)
**Por quÃ© es problema**: **Data leakage** en series temporales de logins

**SoluciÃ³n recomendada**:
```python
# CAMBIAR EN NOTEBOOK (Celda de Split Train/Test):

# ANTES (incorrecto):
X_train, X_test, y_train, y_test = train_test_split(
    X, y,
    test_size=0.2,
    random_state=RANDOM_STATE,
    stratify=y  # âŒ Split aleatorio
)

# DESPUÃ‰S (correcto):
# Ordenar por timestamp primero
df_sorted = features_df.sort_values('Login Timestamp')

# Split temporal 80/20
train_size = int(0.8 * len(df_sorted))
train_df = df_sorted[:train_size]
test_df = df_sorted[train_size:]

# Separar X e y
X_train = train_df.drop(['label', 'Login Timestamp'], axis=1)
y_train = train_df['label']
X_test = test_df.drop(['label', 'Login Timestamp'], axis=1)
y_test = test_df['label']

print(f"âœ… Temporal Split: Train hasta {train_df['Login Timestamp'].max()}")
print(f"   Test desde {test_df['Login Timestamp'].min()}")
```

**JustificaciÃ³n**: El EDA mostrÃ³ que el dataset cubre 313 dÃ­as (Feb-Dic 2020). Entrenar con primeros meses y validar con Ãºltimos meses simula producciÃ³n real.

#### 2. AGREGAR XGBoost ðŸŸ¡ MEDIA PRIORIDAD

**Problema actual**: Solo tiene Logistic Regression, Random Forest, SVM, Gradient Boosting
**Por quÃ© agregar**: XGBoost/LightGBM son los mejores para datos desbalanceados (segÃºn EDA)

**SoluciÃ³n recomendada**:
```python
# AGREGAR EN CELDA DE CONFIGURACIÃ“N DE MODELOS:

config = {
    'random_state': RANDOM_STATE,
    'logistic_regression': {...},
    'random_forest': {...},
    'svm': {...},
    'gradient_boosting': {...},
    # âœ… AGREGAR:
    'xgboost': {
        'n_estimators': 100,
        'max_depth': 7,
        'learning_rate': 0.1,
        'scale_pos_weight': 603,  # Ratio de desbalance
        'subsample': 0.8,
        'colsample_bytree': 0.8,
        'eval_metric': 'aucpr'  # Mejor para desbalance
    }
}
```

**Agregar en `train.py`**:
```python
from xgboost import XGBClassifier

# En funciÃ³n train_models:
if 'xgboost' in config:
    print("\nâ³ Entrenando XGBoost...")
    xgb_model = XGBClassifier(
        n_estimators=config['xgboost']['n_estimators'],
        max_depth=config['xgboost']['max_depth'],
        learning_rate=config['xgboost']['learning_rate'],
        scale_pos_weight=config['xgboost']['scale_pos_weight'],
        subsample=config['xgboost']['subsample'],
        colsample_bytree=config['xgboost']['colsample_bytree'],
        eval_metric=config['xgboost']['eval_metric'],
        random_state=config['random_state'],
        use_label_encoder=False
    )
    xgb_model.fit(X_train, y_train)
    # ... (resto del cÃ³digo de evaluaciÃ³n)
```

#### 3. SMOTE para Oversampling ðŸŸ¡ MEDIA PRIORIDAD

**Problema actual**: No balancea el training set
**Por quÃ© agregar**: SMOTE genera muestras sintÃ©ticas de ATOs

**SoluciÃ³n recomendada**:
```python
# AGREGAR EN CELDA DESPUÃ‰S DE SPLIT (antes de entrenar):

from imblearn.over_sampling import SMOTE

print("\nâ³ Aplicando SMOTE al training set...")
smote = SMOTE(random_state=RANDOM_STATE, sampling_strategy=0.1)  # 10% minoritaria
X_train_sm, y_train_sm = smote.fit_resample(X_train, y_train)

print(f"   ANTES SMOTE: {len(y_train):,} samples")
print(f"   DESPUÃ‰S SMOTE: {len(y_train_sm):,} samples")
print(f"   ATOs generados: {y_train_sm.sum() - y_train.sum()}")

# Usar X_train_sm, y_train_sm para entrenar
```

**Nota**: SMOTE solo en TRAIN, nunca en TEST.

#### 4. Threshold Tuning ðŸŸ¡ MEDIA PRIORIDAD

**Problema actual**: Usa threshold default (0.5) para clasificaciÃ³n
**Por quÃ© cambiar**: Con desbalance extremo, threshold Ã³ptimo es mucho menor

**SoluciÃ³n recomendada**:
```python
# AGREGAR CELDA NUEVA DESPUÃ‰S DE SELECCIONAR MEJOR MODELO:

from sklearn.metrics import precision_recall_curve

print("=" * 80)
print("ðŸŽ¯ THRESHOLD TUNING")
print("=" * 80)

# Obtener probabilidades del mejor modelo
y_pred_proba = best_model.predict_proba(X_test)[:, 1]

# Calcular curva Precision-Recall
precision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)

# Encontrar threshold Ã³ptimo (maximizar F1-Score)
f1_scores = 2 * (precision * recall) / (precision + recall + 1e-10)
optimal_idx = np.argmax(f1_scores)
optimal_threshold = thresholds[optimal_idx]

print(f"\nðŸ“Š THRESHOLD ANALYSIS:")
print(f"   Default threshold: 0.5")
print(f"   Optimal threshold: {optimal_threshold:.4f}")
print(f"   F1-Score @ default: {f1_scores[np.where(thresholds >= 0.5)[0][0]]:.4f}")
print(f"   F1-Score @ optimal: {f1_scores[optimal_idx]:.4f}")

# Predecir con threshold Ã³ptimo
y_pred_tuned = (y_pred_proba >= optimal_threshold).astype(int)

# Evaluar con threshold optimizado
metrics_tuned = evaluate_model(y_test, y_pred_tuned, y_pred_proba, f"{best_model_name} (Tuned)")
```

### ðŸŸ¢ LO QUE SE PUEDE AGREGAR (Opcional)

#### 5. Feature Importance Analysis

```python
# AGREGAR CELDA NUEVA DESPUÃ‰S DE ENTRENAR MEJOR MODELO:

if hasattr(best_model, 'feature_importances_'):
    # Random Forest, XGBoost, Gradient Boosting
    importances = best_model.feature_importances_
    feature_names = X_train.columns

    # Top 20 features mÃ¡s importantes
    indices = np.argsort(importances)[::-1][:20]

    plt.figure(figsize=(12, 8))
    plt.bar(range(20), importances[indices])
    plt.xticks(range(20), [feature_names[i] for i in indices], rotation=90)
    plt.title('Top 20 Features MÃ¡s Importantes')
    plt.ylabel('Importancia')
    plt.tight_layout()
    plt.savefig(f'{OUTPUT_DIR}/reports/feature_importance.png', dpi=300)
    plt.show()
```

#### 6. AnÃ¡lisis de Errores (FP y FN)

```python
# AGREGAR CELDA NUEVA AL FINAL:

print("=" * 80)
print("ðŸ” ANÃLISIS DE ERRORES")
print("=" * 80)

# False Positives
fp_mask = (y_test == 0) & (y_pred == 1)
fp_df = X_test[fp_mask]

print(f"\nðŸ“Š FALSE POSITIVES (FP): {fp_mask.sum()}")
print(f"   Usuarios normales clasificados como ATO")
if len(fp_df) > 0:
    print(f"\n   Top features en FP:")
    print(fp_df.describe())

# False Negatives
fn_mask = (y_test == 1) & (y_pred == 0)
fn_df = X_test[fn_mask]

print(f"\nðŸ“Š FALSE NEGATIVES (FN): {fn_mask.sum()}")
print(f"   ATOs reales NO detectados")
if len(fn_df) > 0:
    print(f"\n   Top features en FN:")
    print(fn_df.describe())
```

### âŒ LO QUE DEBE QUITARSE (Simplificar)

#### 1. Chunk Processing (Ya no necesario)

**RazÃ³n**: Dataset reducido tiene solo 85K registros, cabe completamente en RAM.

**QuÃ© hacer**: Simplificar notebook para cargar dataset completo de una vez:

```python
# SIMPLIFICAR CELDAS DE FASE 2-3:

# ANTES (con chunks):
for chunk in pd.read_csv(DATASET_PATH, chunksize=CHUNK_SIZE):
    # ... procesar chunks ...

# DESPUÃ‰S (sin chunks):
features_df = pd.read_csv(DATASET_PATH)
features_df, encoders = engineer_features(features_df, fit_encoders=True)
```

#### 2. Temp Chunks Directory

**RazÃ³n**: No se necesita guardar chunks temporales.

**QuÃ© hacer**: Eliminar direcciÃ³n `TEMP_DIR` del notebook.

---

## 6. PLAN DE ACCIÃ“N

### ðŸŽ¯ OPCIÃ“N RECOMENDADA: Modificar Notebook con Mejoras

#### Cambios a Realizar (en orden de prioridad)

1. **ðŸ”´ CRÃTICO - Temporal Split** (5 min)
   - Cambiar `train_test_split` por split temporal
   - Evita data leakage

2. **ðŸ”´ CRÃTICO - Quitar Chunk Processing** (5 min)
   - Dataset reducido cabe en RAM
   - Simplifica cÃ³digo

3. **ðŸŸ¡ IMPORTANTE - Agregar XGBoost** (10 min)
   - Mejor modelo para desbalance
   - Instalar: `pip install xgboost`

4. **ðŸŸ¡ IMPORTANTE - Agregar SMOTE** (5 min)
   - Balancea training set
   - Instalar: `pip install imbalanced-learn`

5. **ðŸŸ¡ IMPORTANTE - Threshold Tuning** (10 min)
   - Optimiza Precision/Recall
   - Maximiza F1-Score

6. **ðŸŸ¢ OPCIONAL - Feature Importance** (5 min)
   - Identifica features clave
   - VisualizaciÃ³n Ãºtil

### ðŸ“‹ Checklist de ImplementaciÃ³n

```
Notebook de Modelado:
[ ] Actualizar path a rba_reduced.csv
[ ] Quitar chunk processing (simplificar a carga directa)
[ ] Cambiar train_test_split por temporal split
[ ] Agregar XGBoost al config
[ ] Agregar SMOTE despuÃ©s de split
[ ] Agregar threshold tuning despuÃ©s de mejor modelo
[ ] Agregar feature importance (opcional)
[ ] Actualizar celdas de tÃ­tulos (mencionar "Dataset Reducido")

Scripts de Training (train.py):
[ ] Agregar XGBClassifier import
[ ] Agregar funciÃ³n de entrenamiento XGBoost
[ ] Actualizar evaluaciÃ³n de modelos

Dependencias:
[ ] pip install xgboost
[ ] pip install imbalanced-learn
```

### â±ï¸ Tiempo Estimado

- **Cambios crÃ­ticos**: 15-20 minutos
- **Cambios importantes**: 25-30 minutos
- **Cambios opcionales**: 5-10 minutos
- **Total**: 45-60 minutos

### ðŸš€ EjecuciÃ³n del Notebook

Una vez modificado:

```bash
cd Suspicious-Login-Activity/modeling/notebooks
jupyter notebook Account_Takeover_Detection_Modeling.ipynb

# En Jupyter:
# 1. Kernel â†’ Restart & Run All
# 2. Esperar 15-30 minutos
# 3. Revisar resultados
```

**Tiempo de ejecuciÃ³n esperado**: 15-30 minutos (vs 15-40 con dataset grande)

---

## 7. CONSIDERACIONES PARA CAMBIO DE UBICACIONES

### ðŸŒ LÃ³gica GeogrÃ¡fica a Mantener

Cuando cambies ubicaciones a paÃ­ses cercanos a ti (ej: MÃ©xico, Colombia, etc.), **DEBES MANTENER ESTA LÃ“GICA**:

#### 1. PaÃ­s Dominante Normal

- **Actual**: Noruega (NO) - 45.2% de casos normales
- **Futuro**: Tu paÃ­s (ej: MÃ©xico - MX) - ~45% de casos normales

#### 2. PaÃ­s Dominante ATOs

- **Actual**: Rumania (RO) - 56% de ATOs (139.7x sobre-representado)
- **Futuro**: PaÃ­s lejano (ej: Rumania, Argentina, India) - ~56% de ATOs

**IMPORTANTE**: El paÃ­s de ATOs debe ser:
- DIFERENTE al paÃ­s normal dominante
- LEJANO geogrÃ¡ficamente (>5,000 km)
- Sobre-representado en ATOs (ratio alto)

#### 3. Cambios de PaÃ­s

- **98.6% de ATOs tienen cambio de paÃ­s**
- Este patrÃ³n DEBE mantenerse despuÃ©s del cambio
- Feature `Country_Changed` es CRÃTICA para detecciÃ³n

#### 4. Round-Trip Time

- Debe reflejar distancia geogrÃ¡fica
- ATOs desde paÃ­ses lejanos â†’ RTT mÃ¡s alto
- Ejemplos:
  - MÃ©xico â†’ Rumania: ~200-300ms
  - MÃ©xico â†’ India: ~300-400ms
  - MÃ©xico â†’ Argentina: ~150-250ms

#### 5. Regiones y Ciudades

- Usar nombres REALES (no inventar)
- Consultar bases de datos de geolocalizaciÃ³n
- Mantener coherencia regiÃ³n-ciudad-paÃ­s

### ðŸ› ï¸ Script de Cambio de Ubicaciones

**RecomendaciÃ³n**: Crear script Python para cambiar ubicaciones de forma programÃ¡tica, NO manual.

```python
# Ejemplo de lÃ³gica:
country_mapping = {
    'NO': 'MX',  # Noruega â†’ MÃ©xico (normal)
    'RO': 'RO',  # Rumania â†’ Rumania (ATOs) - mantener lejano
    'US': 'CO',  # USA â†’ Colombia
    'BR': 'AR',  # Brasil â†’ Argentina
    # ...
}

# Aplicar mapping
df['Country'] = df['Country'].map(country_mapping)

# Ajustar regiones/ciudades coherentemente
# ...
```

**CRÃTICO**: NO cambiar ubicaciones arbitrariamente. Usar anÃ¡lisis geogrÃ¡fico de este reporte para guiar cambios.

---

## 8. MÃ‰TRICAS ESPERADAS

### ðŸŽ¯ Baseline (Sin mejoras)

Con el notebook actual (sin modificaciones):

- **F1-Score**: 0.60-0.75
- **Recall**: 0.65-0.80
- **Precision**: 0.55-0.70
- **ROC-AUC**: 0.85-0.92
- **AUC-PR**: 0.40-0.60

### â­ Con Mejoras Implementadas

Con las mejoras recomendadas (Temporal Split + XGBoost + SMOTE + Threshold Tuning):

- **F1-Score**: 0.75-0.90 â¬†ï¸ (+15-20%)
- **Recall**: 0.80-0.95 â¬†ï¸ (+15-20%)
- **Precision**: 0.70-0.85 â¬†ï¸ (+15%)
- **ROC-AUC**: 0.90-0.97 â¬†ï¸ (+5-7%)
- **AUC-PR**: 0.60-0.80 â¬†ï¸ (+20-30%)

**Modelo esperado mejor**: **XGBoost** (basado en EDA y benchmarks de industria)

---

## 9. PRÃ“XIMOS PASOS DESPUÃ‰S DEL MODELADO

Una vez que tengas el modelo entrenado:

### 1. API REST (Similar a Phishing)

```bash
cd Suspicious-Login-Activity/modeling
mkdir api
cd api

# Copiar estructura de Phishing/modeling/api/
cp ../../../Phishing/modeling/api/app.py .
cp ../../../Phishing/modeling/api/predictor.py .
cp ../../../Phishing/modeling/api/requirements.txt .

# Adaptar para Account Takeover
# ... (modificar endpoints, features, modelo)
```

### 2. Conectar Frontend

```javascript
// En frontend/src/services/ataquesSospechososService.js
// Cambiar mock por API real:

export const predictAtaquesSospechosos = async (data) => {
  const response = await axios.post('http://localhost:8001/predict', data);
  return response.data;
};
```

### 3. Testing End-to-End

1. Iniciar API: `uvicorn app:app --port 8001 --reload`
2. Iniciar Frontend: `npm run dev`
3. Probar formulario de "Ataques Sospechosos"
4. Verificar predicciones correctas

---

## 10. CONCLUSIONES FINALES

### âœ… Logros Alcanzados

1. **Dataset Reducido**: 85K registros (<100K âœ“), mÃ¡s rÃ¡pido de entrenar
2. **AnÃ¡lisis GeogrÃ¡fico**: Patrones identificados, guÃ­a para cambio de ubicaciones
3. **EDA Completo**: 9 fases, hallazgos clave documentados
4. **Recomendaciones Concretas**: QuÃ© agregar, quitar, cambiar en notebook

### ðŸŽ¯ Objetivo Claro

**Detectar Account Takeover** (NO Brute Force):
- 99.3% de ATOs son logins exitosos
- Detectar por: paÃ­s diferente, IP nueva, dispositivo diferente
- Cambio de paÃ­s es seÃ±al MÃS FUERTE (98.6% de ATOs)

### ðŸš€ Camino a Seguir

**OpciÃ³n Recomendada**: Modificar notebook con mejoras (45-60 min) â†’ Ejecutar (15-30 min) â†’ Analizar resultados

**Resultado Esperado**: F1-Score 0.75-0.90 con XGBoost, listo para API y frontend.

---

## ðŸ“š REFERENCIAS

- **Dataset**: RBA Dataset (DAS Group - KIT)
- **Paper Original**: "Risk-Based Authentication in Cloud Environments"
- **TÃ©cnicas**: SMOTE (Chawla et al., 2002), XGBoost (Chen & Guestrin, 2016)
- **MÃ©tricas**: AUC-PR para desbalance (Saito & Rehmsmeier, 2015)

---

**Fin del Reporte**

Fecha: 2026-01-13
Generado por: Claude Code
Dataset: RBA Reducido (85,141 registros)
