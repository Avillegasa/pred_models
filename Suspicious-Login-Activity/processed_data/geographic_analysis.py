"""
AN√ÅLISIS GEOGR√ÅFICO PROFUNDO - Dataset RBA Reducido

Analiza patrones geogr√°ficos para entender:
1. Distribuci√≥n de ATOs vs Normal por pa√≠s/regi√≥n
2. Distancias entre logins consecutivos por usuario
3. Patrones de "Impossible Travel" (velocidad f√≠sica imposible)
4. Correlaci√≥n entre distancia y Login Successful
5. Round-Trip Time vs Distancia geogr√°fica
6. Clusters geogr√°ficos de ataques

Objetivo: Entender l√≥gica geogr√°fica ANTES de cambiar ubicaciones
"""

import pandas as pd
import numpy as np
from datetime import datetime
import warnings
warnings.filterwarnings('ignore')

# Configuraci√≥n
DATASET = "rba_reduced.csv"

print("=" * 80)
print("   AN√ÅLISIS GEOGR√ÅFICO PROFUNDO - RBA Dataset")
print("=" * 80)
print(f"\nüìÖ Fecha: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print(f"üìÅ Dataset: {DATASET}")

# Cargar dataset
print("\n‚è≥ Cargando dataset...")
df = pd.read_csv(DATASET)
df['Login Timestamp'] = pd.to_datetime(df['Login Timestamp'])

print(f"‚úÖ Dataset cargado: {len(df):,} registros")
print(f"   ‚Ä¢ Account Takeover: {df['Is Account Takeover'].sum()}")
print(f"   ‚Ä¢ Normal: {len(df) - df['Is Account Takeover'].sum():,}")

# ============================================================================
# 1. DISTRIBUCI√ìN GEOGR√ÅFICA: ATOs vs Normal
# ============================================================================
print("\n" + "=" * 80)
print("1. DISTRIBUCI√ìN GEOGR√ÅFICA: ATOs vs Normal")
print("=" * 80)

ato_df = df[df['Is Account Takeover'] == True]
normal_df = df[df['Is Account Takeover'] == False]

print(f"\nüìä PA√çSES EN ACCOUNT TAKEOVER (Top 10):")
ato_countries = ato_df['Country'].value_counts()
for country, count in ato_countries.head(10).items():
    pct = count / len(ato_df) * 100
    print(f"   {country}: {count} casos ({pct:.1f}%)")

print(f"\nüìä PA√çSES EN CASOS NORMALES (Top 10):")
normal_countries = normal_df['Country'].value_counts()
for country, count in normal_countries.head(10).items():
    pct = count / len(normal_df) * 100
    print(f"   {country}: {count:,} casos ({pct:.2f}%)")

# Pa√≠ses que aparecen M√ÅS en ATOs que en normales
print(f"\n‚ö†Ô∏è  PA√çSES SOBRE-REPRESENTADOS EN ATOs:")
for country in ato_countries.index[:10]:
    ato_pct = (ato_countries.get(country, 0) / len(ato_df)) * 100
    normal_pct = (normal_countries.get(country, 0) / len(normal_df)) * 100
    ratio = ato_pct / normal_pct if normal_pct > 0 else float('inf')

    if ratio > 5:  # M√°s de 5x sobre-representado
        print(f"   {country}: {ratio:.1f}x m√°s frecuente en ATOs que en normales")
        print(f"      ATOs: {ato_pct:.1f}% | Normal: {normal_pct:.2f}%")

# ============================================================================
# 2. LOGIN SUCCESS/FAILURE POR PA√çS
# ============================================================================
print("\n" + "=" * 80)
print("2. TASA DE √âXITO/FALLO POR PA√çS")
print("=" * 80)

# Calcular tasa de √©xito por pa√≠s (Top 10 pa√≠ses)
top_10_countries = df['Country'].value_counts().head(10).index

print(f"\nüìä TASA DE LOGIN EXITOSO POR PA√çS (Top 10):")
for country in top_10_countries:
    country_df = df[df['Country'] == country]
    success_rate = country_df['Login Successful'].sum() / len(country_df) * 100
    total = len(country_df)

    # Ver si tiene ATOs
    ato_count = country_df['Is Account Takeover'].sum()
    ato_str = f" | {ato_count} ATOs" if ato_count > 0 else ""

    print(f"   {country:3s}: {success_rate:5.2f}% √©xito ({total:,} logins{ato_str})")

# ============================================================================
# 3. ROUND-TRIP TIME (RTT) POR PA√çS
# ============================================================================
print("\n" + "=" * 80)
print("3. ROUND-TRIP TIME (RTT) POR PA√çS")
print("=" * 80)

print(f"\nüìä RTT PROMEDIO POR PA√çS (Top 10 pa√≠ses):")
for country in top_10_countries:
    country_df = df[df['Country'] == country]
    rtt_mean = country_df['Round-Trip Time [ms]'].mean()
    rtt_median = country_df['Round-Trip Time [ms]'].median()

    print(f"   {country:3s}: Media={rtt_mean:6.1f}ms | Mediana={rtt_median:6.1f}ms")

# Comparar RTT en ATOs vs Normal
print(f"\nüìä RTT: ATOs vs Normal:")
rtt_ato = ato_df['Round-Trip Time [ms]'].mean()
rtt_normal = normal_df['Round-Trip Time [ms]'].mean()
print(f"   ATOs:   Media={rtt_ato:.1f}ms | Mediana={ato_df['Round-Trip Time [ms]'].median():.1f}ms")
print(f"   Normal: Media={rtt_normal:.1f}ms | Mediana={normal_df['Round-Trip Time [ms]'].median():.1f}ms")
print(f"   Diferencia: {abs(rtt_ato - rtt_normal):.1f}ms ({((rtt_ato - rtt_normal)/rtt_normal*100):.1f}%)")

# ============================================================================
# 4. AN√ÅLISIS DE CAMBIOS DE PA√çS POR USUARIO
# ============================================================================
print("\n" + "=" * 80)
print("4. CAMBIOS DE PA√çS POR USUARIO")
print("=" * 80)

# Ordenar por usuario y timestamp
df_sorted = df.sort_values(['User ID', 'Login Timestamp'])

# Calcular cambio de pa√≠s
df_sorted['Country_Changed'] = df_sorted.groupby('User ID')['Country'].shift() != df_sorted['Country']
country_changes = df_sorted[df_sorted['Country_Changed'] == True]

print(f"\nüìä ESTAD√çSTICAS DE CAMBIOS DE PA√çS:")
print(f"   Total cambios de pa√≠s: {len(country_changes):,}")
print(f"   Usuarios con cambio de pa√≠s: {country_changes['User ID'].nunique():,}")

# Cambios de pa√≠s en ATOs
ato_country_changes = country_changes[country_changes['Is Account Takeover'] == True]
print(f"\n   En ACCOUNT TAKEOVER:")
print(f"      Cambios de pa√≠s en ATOs: {len(ato_country_changes)}")
print(f"      % de ATOs con cambio de pa√≠s: {len(ato_country_changes)/len(ato_df)*100:.1f}%")

# Cambios de pa√≠s m√°s comunes
print(f"\nüìä CAMBIOS DE PA√çS M√ÅS COMUNES (Top 10):")
# Crear pares de pa√≠s origen ‚Üí destino
country_transitions = []
for idx, row in country_changes.iterrows():
    prev_idx = df_sorted[df_sorted['User ID'] == row['User ID']].index
    prev_idx = prev_idx[prev_idx < idx]
    if len(prev_idx) > 0:
        prev_country = df_sorted.loc[prev_idx[-1], 'Country']
        curr_country = row['Country']
        country_transitions.append(f"{prev_country} ‚Üí {curr_country}")

if len(country_transitions) > 0:
    from collections import Counter
    transition_counts = Counter(country_transitions)
    for transition, count in transition_counts.most_common(10):
        print(f"   {transition}: {count:,} veces")

# ============================================================================
# 5. REGIONES Y CIUDADES EN ATOs
# ============================================================================
print("\n" + "=" * 80)
print("5. REGIONES Y CIUDADES EN ACCOUNT TAKEOVER")
print("=" * 80)

print(f"\nüìä TOP 10 REGIONES EN ATOs:")
ato_regions = ato_df['Region'].value_counts().head(10)
for region, count in ato_regions.items():
    pct = count / len(ato_df) * 100
    print(f"   {region}: {count} casos ({pct:.1f}%)")

print(f"\nüìä TOP 10 CIUDADES EN ATOs:")
ato_cities = ato_df['City'].value_counts().head(10)
for city, count in ato_cities.items():
    pct = count / len(ato_df) * 100
    print(f"   {city}: {count} casos ({pct:.1f}%)")

# ============================================================================
# 6. IS ATTACK IP - Relaci√≥n con Pa√≠s
# ============================================================================
print("\n" + "=" * 80)
print("6. IPs DE ATAQUE POR PA√çS")
print("=" * 80)

attack_ips = df[df['Is Attack IP'] == True]
print(f"\nüìä IPs marcadas como ataque: {len(attack_ips):,}")
print(f"   Pa√≠ses con IPs de ataque: {attack_ips['Country'].nunique()}")

if len(attack_ips) > 0:
    print(f"\nüìä TOP 10 PA√çSES CON IPs DE ATAQUE:")
    attack_countries = attack_ips['Country'].value_counts().head(10)
    for country, count in attack_countries.items():
        pct = count / len(attack_ips) * 100
        print(f"   {country}: {count:,} IPs de ataque ({pct:.2f}%)")

# ============================================================================
# 7. CONCLUSIONES Y PATRONES IDENTIFICADOS
# ============================================================================
print("\n" + "=" * 80)
print("7. CONCLUSIONES Y PATRONES GEOGR√ÅFICOS")
print("=" * 80)

print(f"\nüéØ PATRONES IDENTIFICADOS:")

# Patr√≥n 1: Pa√≠s dominante en ATOs
main_ato_country = ato_countries.index[0]
main_ato_pct = (ato_countries.iloc[0] / len(ato_df)) * 100
print(f"\n1. PA√çS DOMINANTE EN ATOs: {main_ato_country}")
print(f"   ‚Ä¢ {main_ato_pct:.1f}% de todos los ATOs provienen de {main_ato_country}")
print(f"   ‚Ä¢ Esto es {main_ato_pct / (normal_countries.get(main_ato_country, 1) / len(normal_df) * 100):.1f}x m√°s que en casos normales")

# Patr√≥n 2: Pa√≠s dominante en casos normales
main_normal_country = normal_countries.index[0]
main_normal_pct = (normal_countries.iloc[0] / len(normal_df)) * 100
print(f"\n2. PA√çS DOMINANTE EN NORMALES: {main_normal_country}")
print(f"   ‚Ä¢ {main_normal_pct:.2f}% de casos normales desde {main_normal_country}")
print(f"   ‚Ä¢ Sistema SSO esperado en {main_normal_country}")

# Patr√≥n 3: Cambios de pa√≠s
print(f"\n3. CAMBIOS DE PA√çS:")
print(f"   ‚Ä¢ {len(country_changes):,} cambios de pa√≠s detectados")
print(f"   ‚Ä¢ {len(ato_country_changes)/len(ato_df)*100:.1f}% de ATOs tienen cambio de pa√≠s")
print(f"   ‚Ä¢ Cambio de pa√≠s es SE√ëAL FUERTE de ATO")

# Patr√≥n 4: RTT
print(f"\n4. ROUND-TRIP TIME:")
print(f"   ‚Ä¢ ATOs tienen RTT promedio: {rtt_ato:.1f}ms")
print(f"   ‚Ä¢ Normal tiene RTT promedio: {rtt_normal:.1f}ms")
if abs(rtt_ato - rtt_normal) > 10:
    print(f"   ‚Ä¢ Diferencia significativa: RTT puede ser feature √∫til")
else:
    print(f"   ‚Ä¢ Diferencia peque√±a: RTT no es discriminante fuerte")

# ============================================================================
# 8. RECOMENDACIONES PARA CAMBIO DE UBICACIONES
# ============================================================================
print("\n" + "=" * 80)
print("8. RECOMENDACIONES PARA CAMBIO DE UBICACIONES")
print("=" * 80)

print(f"\nüí° CONSIDERACIONES IMPORTANTES:")
print(f"\n1. MANTENER L√ìGICA DE PA√çSES:")
print(f"   ‚Ä¢ Pa√≠s normal dominante: {main_normal_country} (esperado, usuarios leg√≠timos)")
print(f"   ‚Ä¢ Pa√≠s ATO dominante: {main_ato_country} (ataques desde aqu√≠)")
print(f"   ‚Ä¢ Al cambiar ubicaciones, MANTENER esta relaci√≥n:")
print(f"     - Usuarios normales mayormente de 1 pa√≠s (ej: tu pa√≠s)")
print(f"     - ATOs desde pa√≠ses DIFERENTES (anomal√≠a geogr√°fica)")

print(f"\n2. PRESERVAR DISTANCIAS RELATIVAS:")
print(f"   ‚Ä¢ ATOs exitosos vienen de pa√≠ses LEJANOS al pa√≠s principal")
print(f"   ‚Ä¢ Cambiar ubicaciones manteniendo distancias similares")
print(f"   ‚Ä¢ Ejemplo: Si cambias a M√©xico:")
print(f"     - Normal: M√©xico (mayor√≠a)")
print(f"     - ATOs: Rumania ‚Üí Argentina/Chile (lejanos)")

print(f"\n3. ROUND-TRIP TIME:")
print(f"   ‚Ä¢ RTT aumenta con distancia geogr√°fica")
print(f"   ‚Ä¢ Al cambiar ubicaciones, RTT debe reflejar distancia")
print(f"   ‚Ä¢ Ejemplo: M√©xico ‚Üí Europa = 150-250ms")

print(f"\n4. REGIONES Y CIUDADES:")
print(f"   ‚Ä¢ Usar regiones/ciudades REALES del pa√≠s elegido")
print(f"   ‚Ä¢ No inventar nombres, usar geolocalizaci√≥n real")
print(f"   ‚Ä¢ Dataset tiene {df['Region'].nunique()} regiones, {df['City'].nunique()} ciudades")

print(f"\n5. CAMBIOS DE PA√çS:")
print(f"   ‚Ä¢ {len(ato_country_changes)/len(ato_df)*100:.1f}% de ATOs tienen cambio de pa√≠s")
print(f"   ‚Ä¢ Este patr√≥n DEBE mantenerse despu√©s del cambio")
print(f"   ‚Ä¢ Feature 'Country_Changed' es CR√çTICA para detecci√≥n")

print("\n" + "=" * 80)
print("‚úÖ AN√ÅLISIS GEOGR√ÅFICO COMPLETADO")
print("=" * 80)

print(f"\nüìã ARCHIVOS GENERADOS:")
print(f"   ‚Ä¢ An√°lisis impreso en consola")
print(f"   ‚Ä¢ Dataset analizado: {DATASET}")

print(f"\nüéØ PR√ìXIMOS PASOS:")
print(f"   1. Revisar patrones geogr√°ficos identificados")
print(f"   2. Planificar cambio de ubicaciones manteniendo l√≥gica")
print(f"   3. Ejecutar EDA completo con dataset reducido")
print(f"   4. Entrenar modelo con dataset optimizado")

print("\n" + "=" * 80)
